<h1>Drawing With Points in WebGL</h1>

<h2>Creating a context</h2>
<p>
    All WebGL graphics are rendered within a <code>&ltcanvas&gt</code> html attribute. Before any graphics can be rendered, you must first access a canvas object in the DOM.
</p>

<pre class="js"><code>
const <var>canvas</var> = document.querySelector("#canvas");
</code></pre>

<p>
    Next, create a WebGL context. The context gives you a handle with which 
    you can call WebGL functions for a particular canvas. While WebGL is widely 
    available and supported by most browsers, some users may be using outdated 
    browsers or have computers with severe resource limitations. In this case, 
    WebGL may not be available, so it's a good idea to provide error handling for this scenario.
</p>

<pre class="js"><code>
const <var>gl</var> = canvas.getContext("webgl");

if (gl === null) {
    alert("Unable to initialize WebGL. Your browser or machine may not support it");
    return;
}
</code></pre>

<h2>Creating shaders</h2>
<h3>Vertex Shader</h3>

<p>
    All shapes are initially rendered as a collection of vertices defining where the sides of the shape meet.
    Shaders are written in GLSL, a C like language built specifically for creating shaders. In WebGL, you
    can embed your GLSL code into JavaScript as a string.
</p>

<pre class="js"><code>
const vsSource = `
    attribute vec4 aVertexPosition;

    uniform mat4 uModelViewMatrix;
    uniform mat4 uProjectionMatrix;

    void main() {
        gl_Position = uProjectionMatrix * uModelViewMatrix * aVertexPosition;
        gl_PointSize = 5.0;
    }
`;
</code></pre>

<p>
    In the first three lines of this shader, variables are declared: aVertexPosition, uModelViewMatrix, and uProjectionMatrix.
    aVertexPosition is declared as an attribute vec4. An attribute can be thought of as a runtime argument from other languages.
    Each time the vsSource shader is called, you will provide it with a new value for aVertexPosition. vec4 indicates that 
    aVertexPosition is a vector, or one dimensional array, of floating point numbers. In 3D rendering, a vector must be defined in
    relation to the X, Y, Z, and W axis; however, for this tutorial you will just focus on the X and Y axis. 
</p>

<p>
    uModelViewMatrix and uProjectionMatrix are defined as uniform mat4 variables. Whereas attributes can be compared to runtime 
    parameters, uniforms are similar to global variables. At a later point in the program, you will define these values and they
    will remain static for the duration of the rendering logic. mat4 indicates that these variables are 4x4 matrices of floating
    point numbers. In 3D graphics, the 3D object defined by a collection of vertices must be "flattened" into the 2D space of the 
    screen. This is accomplished by multiplying the projection matrix, model view matrix, and the vertex vector. For now, don't
    worry about the mathematical specifics, instead just understand that <code>gl_Position = uProjectionMatrix * uModelViewMatrix * aVertexPosition;</code>
    renders the vertex on screen at the proper X, Y coordinates.
</p>

<p>
    Finally, defining <code>gl_PointSize</code> indicates to WebGL how large each vertex should be drawn. This is not set when vertices
    are being used to compose more complicated shapes, but because this lab focuses on drawing vertices as stand alone points, it is necessary.
</p>

<h3>Fragment Shader</h3>

<p>
    All objects, either 2D or 3D, in WebGL are initially represented as a collection of vertices. For example, a triangle is represented by 
    three vertices each representing one corner. While vertex shaders are used to define the position of a vertex and, in this case, their size,
    fragment shaders inform WebGL about how the shapes composed by WebGL should be rendered, such as what color items should be. 
</p>

<pre class="js"><code>
    const fsSource = `
        void main() {
            gl_FragColor = vec4(1.0, 1.0, 0.0, 1.0);
        }
    `;
</code></pre>

<p>
    Similar to how <code>gl_PointSize</code> defines how large a vertex should be drawn, <code>gl_FragColor</code>
    tells WebGL what color a fragment should be drawn in RGBA format. The above example will set the drawn point
    to yellow.
</p>

<h3>Initializing the Shaders</h3>

<p>
    We've defined two shaders, but the real magic of WebGL is being able to compile and load these programs
    on to a user's GPU to render graphical scenes as though they were running natively on their desktop.
</p>

<pre class="js"><code>
    //
    // creates a shader of the given type, uploads the source and
    // compiles it.
    //
    function loadShader(gl, type, source) {
        const shader = gl.createShader(type);
    
        // Send the source to the shader object
    
        gl.shaderSource(shader, source);
    
        // Compile the shader program
    
        gl.compileShader(shader);
    
        // See if it compiled successfully
    
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
            alert('An error occurred compiling the shaders: ' + gl.getShaderInfoLog(shader));
            gl.deleteShader(shader);
            return null;
        }
    
        return shader;
    }
</code></pre>

<p>
    The <code>loadShader</code> function first creates a shader object, then loads the source code for the program and
    compiles it using the WebGL context. If this is accomplished successfully, the shader object is returned to the caller.
</p>

<p>
    In WebGL, individual shaders are used to compose <code>Program</code> objects. Let's take a look at the 
    <code>initShaderProgram</code> code to see how this is done.
</p>

<pre class="js"><code>
    //
    // creates a shader of the given type, uploads the source and
    // compiles it.
    //
    function loadShader(gl, type, source) {
        const shader = gl.createShader(type);
    
        // Send the source to the shader object
    
        gl.shaderSource(shader, source);
    
        // Compile the shader program
    
        gl.compileShader(shader);
    
        // See if it compiled successfully
    
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
            alert('An error occurred compiling the shaders: ' + gl.getShaderInfoLog(shader));
            gl.deleteShader(shader);
            return null;
        }
    
        return shader;
    }
</code></pre>

<h2>Instantiating Buffers</h2>

<p>
    We've compiled and loaded our shaders into a program. Next, let's load some data for our 
    vertex shader to operate on.
</p>

<pre class="js"><code>
    function initBuffers(gl) {

        // Create a buffer for the square's positions.
    
        const positionBuffer = gl.createBuffer();
    
        // Select the positionBuffer as the one to apply buffer
        // operations to from here out.
    
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
    
        // Now create an array of positions for the square.
    
        const positions = [
            -1.0,  1.0,
             1.0,  1.0,
            -1.0, -1.0,
             1.0, -1.0
        ];
        const num_vertices = Math.floor(positions.length / 2);
    
        // Now pass the list of positions into WebGL to build the
        // shape. We do this by creating a Float32Array from the
        // JavaScript array, then use it to fill the current buffer.
    
        gl.bufferData(gl.ARRAY_BUFFER,
            new Float32Array(positions),
            gl.STATIC_DRAW);
    
        return [{
            position: positionBuffer,
        }, num_vertices];
    }
</code></pre>

<p>
    First, we call <code>gl.createBuffer</code> to create memory we can load vertex positions into.
    Then, we bind the buffer so that operations called by WebGL will operate on our <code>positionBuffer</code>. 
    We can then take a JavaScript array of floating point numbers, and read it into our WebGL buffer using 
    <code>bufferData</code>. Finally, we return an object containing the WebGL buffer and the number of 
    vertices the buffer contains.
</p>

<h2>Drawing the Scene</h2>

<p>
    We've nearly completed our first simple WebGL program. All we need to do now is put the pieces
    together and render the vertices we've defined.
</p>

<pre class="js"><code>
    function drawScene(gl, programInfo, buffers, num_vertices) {
        gl.clearColor(0.0, 0.0, 0.0, 1.0);  // Clear to black, fully opaque
        gl.clearDepth(1.0);                 // Clear everything
        gl.enable(gl.DEPTH_TEST);           // Enable depth testing
        gl.depthFunc(gl.LEQUAL);            // Near things obscure far things
    
        // Clear the canvas before we start drawing on it.
    
        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
    
        // Create a perspective matrix, a special matrix that is
        // used to simulate the distortion of perspective in a camera.
        // Our field of view is 45 degrees, with a width/height
        // ratio that matches the display size of the canvas
        // and we only want to see objects between 0.1 units
        // and 100 units away from the camera.
    
        const fieldOfView = 45 * Math.PI / 180;   // in radians
        const aspect = gl.canvas.clientWidth / gl.canvas.clientHeight;
        const zNear = 0.1;
        const zFar = 100.0;
        const projectionMatrix = mat4.create();
    
        // note: glmatrix.js always has the first argument
        // as the destination to receive the result.
        mat4.perspective(projectionMatrix,
            fieldOfView,
            aspect,
            zNear,
            zFar);
    
        // Set the drawing position to the "identity" point, which is
        // the center of the scene.
        const modelViewMatrix = mat4.create();
    
        // Now move the drawing position a bit to where we want to
        // start drawing the square.
    
        mat4.translate(modelViewMatrix,     // destination matrix
            modelViewMatrix,     // matrix to translate
            [-0.0, 0.0, -6.0]);  // amount to translate
    
        // Tell WebGL how to pull out the positions from the position
        // buffer into the vertexPosition attribute.
        {
            const numComponents = 2;  // pull out 2 values per iteration
            const type = gl.FLOAT;    // the data in the buffer is 32bit floats
            const normalize = false;  // don't normalize
            const stride = 0;         // how many bytes to get from one set of values to the next
            // 0 = use type and numComponents above
            const offset = 0;         // how many bytes inside the buffer to start from
            gl.bindBuffer(gl.ARRAY_BUFFER, buffers.position);
            gl.vertexAttribPointer(
                programInfo.attribLocations.vertexPosition,
                numComponents,
                type,
                normalize,
                stride,
                offset);
            gl.enableVertexAttribArray(
                programInfo.attribLocations.vertexPosition);
        }
    
        // Tell WebGL to use our program when drawing
    
        gl.useProgram(programInfo.program);
    
        // Set the shader uniforms
    
        gl.uniformMatrix4fv(
            programInfo.uniformLocations.projectionMatrix,
            false,
            projectionMatrix);
        gl.uniformMatrix4fv(
            programInfo.uniformLocations.modelViewMatrix,
            false,
            modelViewMatrix);
    
        {
            const offset = 0;
            gl.drawArrays(gl.POINTS, offset, num_vertices);
        }
    }
</code></pre>

<p>
    There's a lot of information in the above function, but for now let's try to unpack the most important parts.
    First, we set the canvas's background color to be black. We then define a <code>projectionMatrix</code>,
    which defines how wide the camera's view is (field of view) and how far it can see (zFar and zNear). We also inform
    WebGL of the canvas's aspect ratio by telling it how tall and how wide it is. 
</p>

<p>
    An interesting curiosity about OpenGL is that the camera is always located at the origin point (0, 0, 0). Rather
    than moving the camera around a rendered scene, the scene is actually moved around the camera. Since this is a static
    scene, we do not need to worry too much about this for now, but a translation is applied to the <code>modelViewMatrix</code>
    to move everything array from the camera by 6 units. Finally, the <code>drawArrays</code> method is invoked, which draws the 
    vertices we defined on the screen.
</p>

<h2>Exercise</h2>

<p>
    For this exercise, you'll practice simple WebGL drawings using vertex points. Your goal is to alter the code in the 
    Assisted Code tab to draw a smiley face. If you get stuck, you can peak at our implementation by clicking on the 
    Solution tab.
</p>

<p>
    Note: you may want to review the equation of a circle if you've forgotten it.
</p>

<p>
    This tutorial is adapted from this 
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/Tutorial/Adding_2D_content_to_a_WebGL_context">
        MDN article
    </a>
    .
</p>
